{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DATASET"
      ],
      "metadata": {
        "id": "iyT4U5Ohc24L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout \n",
        "from keras.layers import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "m0rF86FoNqRX"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9zZ32ZgcjF1"
      },
      "outputs": [],
      "source": [
        "#!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
        "!wget https://github.com/Diegojfsr/RNA_Trabalho_Pratico_II/blob/main/flowers.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### descompactar o arquivo Zipado\n",
        "\n",
        "#!unzip cats_and_dogs_filtered.zip\n",
        "!unzip flowers.zip"
      ],
      "metadata": {
        "id": "x-EvhqEkemAs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### escluir o arquivo zipado\n",
        "\n",
        "#!rm -rf cats_and_dogs_filtered.zip\n",
        "!rm -rf flowers.zip"
      ],
      "metadata": {
        "id": "qK4yTfv0eyti"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "QtWzO6j-qWqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "cyK4De3-qbcs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Importando as Imagens\n",
        "### Sepando em Train and test\n",
        "## Verificando a quantidade de imagens\n",
        "\n",
        "dataset = os.path.join(os.getcwd(), 'flowers')\n",
        "\n",
        "dataset_train = os.path.join(dataset, 'train')\n",
        "dataset_train_rose = len(os.listdir(os.path.join(dataset_train, 'rose')))\n",
        "dataset_train_tulip = len(os.listdir(os.path.join(dataset_train, 'tulip')))\n",
        "\n",
        "dataset_test = os.path.join(dataset, 'test')\n",
        "dataset_test_rose = len(os.listdir(os.path.join(dataset_test, 'rose')))\n",
        "dataset_test_tulip = len(os.listdir(os.path.join(dataset_test, 'tulip')))\n",
        "\n",
        "print('Train rose: %s' % dataset_train_rose)\n",
        "print('Train tulip: %s' % dataset_train_tulip)\n",
        "print('Test rose: %s' % dataset_test_rose)\n",
        "print('Test tulip: %s' % dataset_test_tulip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTxDHnC5qnXJ",
        "outputId": "782a59f3-f270-4fed-b3b1-fa7653f9ec63"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train rose: 634\n",
            "Train tulip: 794\n",
            "Test rose: 150\n",
            "Test tulip: 190\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre-Processamento"
      ],
      "metadata": {
        "id": "Jchd5vecyiwH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_width = 64\n",
        "image_height = 64\n",
        "image_color_channel = 3\n",
        "image_color_channel_size = 255\n",
        "image_size = (image_width, image_height)\n",
        "image_shape = image_size + (image_color_channel,)\n",
        "\n",
        "batch_size = 32  #quantidade de features trazidas por vez do dataset\n",
        "epochs = 20 #quantidade de X que sera passado pela rede\n",
        "learning_rate = 0.0001 #taxa de aprendizagem\n",
        "\n",
        "class_names = ['rose', 'tulip'] #saida"
      ],
      "metadata": {
        "id": "9tG07wEzxfF6"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_train,\n",
        "    image_size = image_size,\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_iuKde0yheR",
        "outputId": "6e37ff53-78e6-431e-b382-af8614af26ea"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1428 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    dataset_test,\n",
        "    image_size = (image_width, image_height),\n",
        "    batch_size = batch_size,\n",
        "    shuffle = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COmA0NYwyswu",
        "outputId": "c7466ce9-a4be-427b-f4c9-ea22f5235931"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 340 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test_cardinality = tf.data.experimental.cardinality(dataset_test)\n",
        "dataset_test_batches = dataset_test_cardinality // 5\n",
        "\n",
        "dataset_test2 = dataset_test.take(dataset_test_batches)\n",
        "dataset_validation = dataset_test.skip(dataset_test_batches)\n",
        "\n",
        "print('Test Dataset Cardinality: %d' % tf.data.experimental.cardinality(dataset_test))\n",
        "print('Test2 Dataset Cardinality: %d' % tf.data.experimental.cardinality(dataset_test2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4gX3tJ4zJp0",
        "outputId": "0f5881e5-1193-46f9-c927-c4a9ec30f6ed"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Dataset Cardinality: 11\n",
            "Test2 Dataset Cardinality: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "autotune = tf.data.AUTOTUNE\n",
        "\n",
        "dataset_train = dataset_train.prefetch(buffer_size = autotune)\n",
        "dataset_test = dataset_test.prefetch(buffer_size = autotune)\n",
        "dataset_test2 = dataset_test.prefetch(buffer_size = autotune)"
      ],
      "metadata": {
        "id": "5T1i4umn12D0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Função para printar Dataset\n",
        "\n",
        "def plot_dataset(dataset):\n",
        "\n",
        "    plt.gcf().clear()\n",
        "    plt.figure(figsize = (15, 15))\n",
        "\n",
        "    for features, labels in dataset.take(1):\n",
        "\n",
        "        for i in range(9):\n",
        "\n",
        "            plt.subplot(3, 3, i + 1)\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.imshow(features[i].numpy().astype('uint8'))\n",
        "            plt.title(class_names[labels[i]])"
      ],
      "metadata": {
        "id": "qQ8QWAVi2OkK"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dataset(dataset_train)"
      ],
      "metadata": {
        "id": "YbAxifEN2gBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dataset(dataset_test)"
      ],
      "metadata": {
        "id": "in2azXfH2lxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dataset(dataset_test2)"
      ],
      "metadata": {
        "id": "TBJs2Egp2rBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando o Modelo"
      ],
      "metadata": {
        "id": "9-GIQs6B28o4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2)\n",
        "])"
      ],
      "metadata": {
        "id": "nKo6rXuF2-6g"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###Função para Inverter posição das imagens/criando varias imagens apartir de uma\n",
        "\n",
        "def plot_dataset_data_augmentation(dataset):\n",
        "\n",
        "    plt.gcf().clear()\n",
        "    plt.figure(figsize = (15, 15))\n",
        "\n",
        "    for features, _ in dataset.take(1):\n",
        "\n",
        "        feature = features[0]\n",
        "\n",
        "        for i in range(9):\n",
        "\n",
        "            feature_data_augmentation = data_augmentation(tf.expand_dims(feature, 0))\n",
        "\n",
        "            plt.subplot(3, 3, i + 1)\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.imshow(feature_data_augmentation[0] / image_color_channel_size)"
      ],
      "metadata": {
        "id": "YVNIoEoq3GtD"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dataset_data_augmentation(dataset_train)"
      ],
      "metadata": {
        "id": "sBJDvXuZ3Mkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classificação de Camadas"
      ],
      "metadata": {
        "id": "Eb60nFoH3eb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rescaling = tf.keras.layers.experimental.preprocessing.Rescaling(1. / (image_color_channel_size / 2.), offset = -1, input_shape = image_shape)"
      ],
      "metadata": {
        "id": "cRhU9pKO3eFQ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aprendizagem"
      ],
      "metadata": {
        "id": "1hzuk7bE3qqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_transfer_learning = tf.keras.applications.MobileNetV2(input_shape = image_shape, include_top = False, weights = 'imagenet')\n",
        "model_transfer_learning.trainable = False\n",
        "\n",
        "model_transfer_learning.summary()"
      ],
      "metadata": {
        "id": "KwbGPFOK3tVM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3)"
      ],
      "metadata": {
        "id": "HFy3F2oc364t"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo"
      ],
      "metadata": {
        "id": "_QRrEH8k3-P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    rescaling,\n",
        "    data_augmentation,\n",
        "    model_transfer_learning,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate = learning_rate),\n",
        "    loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-X92B4xX3_Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    dataset_train,\n",
        "    validation_data = dataset_test,\n",
        "    epochs = epochs,\n",
        "    callbacks = [\n",
        "        early_stopping\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "ZBKkeKK756VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_model():\n",
        "\n",
        "    accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(epochs)\n",
        "\n",
        "    plt.gcf().clear()\n",
        "    plt.figure(figsize = (15, 8))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.plot(epochs_range, accuracy, label = 'Training Accuracy')\n",
        "    plt.plot(epochs_range, val_accuracy, label = 'Validation Accuracy')\n",
        "    plt.legend(loc = 'lower right')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.plot(epochs_range, loss, label = 'Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label = 'Validation Loss')\n",
        "    plt.legend(loc = 'lower right')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4HQY-5Hv7txV"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model()"
      ],
      "metadata": {
        "id": "BZnCUlaK7yG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avaliando o Modelo"
      ],
      "metadata": {
        "id": "jJpR-aqd72no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_test_loss, dataset_test_accuracy = model.evaluate(dataset_test)\n",
        "\n",
        "print('Dataset Test Loss:     %s' % dataset_test_loss)\n",
        "print('Dataset Test Accuracy: %s' % dataset_test_accuracy)"
      ],
      "metadata": {
        "id": "4uFKbF1m74fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "984e24ad-8ea6-4fa2-a48d-07eb78f27deb"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 1s 105ms/step - loss: 0.5112 - accuracy: 0.7324\n",
            "Dataset Test Loss:     0.5111969113349915\n",
            "Dataset Test Accuracy: 0.7323529124259949\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dataset_predictions(dataset):\n",
        "\n",
        "    features, labels = dataset_test.as_numpy_iterator().next()\n",
        "\n",
        "    predictions = model.predict_on_batch(features).flatten()\n",
        "    predictions = tf.where(predictions < 0.5, 0, 1)\n",
        "\n",
        "    print('Labels:      %s' % labels)\n",
        "    print('Predictions: %s' % predictions.numpy())\n",
        "\n",
        "    plt.gcf().clear()\n",
        "    plt.figure(figsize = (15, 15))\n",
        "\n",
        "    for i in range(9):\n",
        "\n",
        "        plt.subplot(3, 3, i + 1)\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.imshow(features[i].astype('uint8'))\n",
        "        plt.title(class_names[predictions[i]])"
      ],
      "metadata": {
        "id": "ognEcCfc8CPj"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_dataset_predictions(dataset_test)"
      ],
      "metadata": {
        "id": "oTVBqGcR8HVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizando predições com a Rede Neural Treinada"
      ],
      "metadata": {
        "id": "l8MPKYwDL2nF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.preprocessing import image \n",
        "from keras.utils import load_img, img_to_array"
      ],
      "metadata": {
        "id": "dTOZ0tukL4Bv"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#imagem_orig = load_img('/content/flowers/test/tulip/tulip109.jpg')\n",
        "\n",
        "\n",
        "imagem_orig = load_img('/content/flowers/test/rose/rose119.jpg')\n",
        "plt.imshow(imagem_orig)"
      ],
      "metadata": {
        "id": "jMRmzkRvL_bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#realizando  a predição para uma imagem \n",
        "\n",
        "#imagem_teste = load_img('/content/flowers/test/tulip/tulip102.jpg', target_size = (64,64))\n",
        "\n",
        "imagem_teste = load_img('/content/flowers/test/rose/rose119.jpg', target_size = (64,64))\n",
        "plt.imshow(imagem_teste)"
      ],
      "metadata": {
        "id": "KqhOQLqtMMrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste = img_to_array(imagem_teste)"
      ],
      "metadata": {
        "id": "9fBxQPO4MUXy"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste"
      ],
      "metadata": {
        "id": "eyPQjZbnMW4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NA1QP0hRMZuV",
        "outputId": "538c70d2-eec4-40cc-c2e2-8dc27884ab3e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Salvando e Carregando o Modelo Treinado"
      ],
      "metadata": {
        "id": "j-MmxNDQ8M_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Salvando O modelo Treinado\n",
        "model.save('modelRoseTulip.h5')"
      ],
      "metadata": {
        "id": "M2oHWhr58OSF"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carregar o modelo treinado \n",
        "\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "fwQ1odZLPH1c"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.load_model('modelRoseTulip.h5')"
      ],
      "metadata": {
        "id": "J8lnB-tRPLJK"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREDICTIONS | Realizar as prediçoes em uma imagem"
      ],
      "metadata": {
        "id": "6KYha1hw8kr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(image_file):\n",
        "\n",
        "    image = tf.keras.preprocessing.image.load_img(image_file, target_size = image_size)\n",
        "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
        "    image = tf.expand_dims(image, 0)\n",
        "\n",
        "    prediction = model.predict(image)[0][0]\n",
        "\n",
        "    print('Prediction: {0} | {1}'.format(prediction, ('rose' if prediction < 0.5 else 'tulip')))"
      ],
      "metadata": {
        "id": "FlJbZgfL8j-P"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_url(image_fname, image_origin):\n",
        "\n",
        "    image_file = tf.keras.utils.get_file(image_fname, origin = image_origin)\n",
        "    return predict(image_file)"
      ],
      "metadata": {
        "id": "A6hDRxIZ8uOv"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict('/content/flowers/test/tulip/tulip1.jpg')"
      ],
      "metadata": {
        "id": "tecdFcSzlVL7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e404c23e-171f-436e-ba4c-cd2cf757c4b5"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n",
            "Prediction: 0.8285767436027527 | tulip\n"
          ]
        }
      ]
    }
  ]
}
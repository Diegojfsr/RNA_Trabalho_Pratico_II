{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DU_IY_lFluu7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout \n",
        "from keras.layers import BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "####  Criar a Estrutura da Rede Neural"
      ],
      "metadata": {
        "id": "zdz2hHYAAz2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = Sequential()\n",
        "\n",
        "#primeira camada de convolução\n",
        "cnn.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "cnn.add(BatchNormalization())\n",
        "\n",
        "#Pooling\n",
        "cnn.add(MaxPooling2D(pool_size = (2,2)))"
      ],
      "metadata": {
        "id": "HG0acFtq3NhN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#segunda camada de convolução\n",
        "cnn.add(Conv2D(32, (3,3), input_shape = (64, 64, 3), activation = 'relu'))\n",
        "cnn.add(BatchNormalization())\n",
        "\n",
        "#Pooling\n",
        "cnn.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "#Flattening\n",
        "cnn.add(Flatten())"
      ],
      "metadata": {
        "id": "LmKDb12y3TEE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#camada densa \n",
        "\n",
        "cnn.add(Dense(units = 128, activation = 'relu'))\n",
        "cnn.add(Dropout(0.2))\n",
        "cnn.add(Dense(units = 128, activation = 'relu'))\n",
        "cnn.add(Dropout(0.2))\n",
        "cnn.add(Dense(units = 1, activation = 'sigmoid'))\n",
        "\n",
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "jKIGDP8x3X2s"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gerador_treinamento = ImageDataGenerator(rescale = 1./255) \n",
        "                                         #rotation_range = 7,\n",
        "                                         #horizontal_flip = True,\n",
        "                                         #shear_range = 0.2,\n",
        "                                         #height_shift_range = 0.07,\n",
        "                                         #zoom_range = 0.2)"
      ],
      "metadata": {
        "id": "JJcELwWn7yO2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gerador_teste = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "KRwyWsAu70kT"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### descompactar o arquivo Zipado\n",
        "\n",
        "#!unzip cats_and_dogs_filtered.zip\n",
        "!unzip flowers.zip"
      ],
      "metadata": {
        "id": "GkqV4sLk8Azz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### escluir o arquivo zipado\n",
        "\n",
        "#!rm -rf cats_and_dogs_filtered.zip\n",
        "!rm -rf flowers.zip"
      ],
      "metadata": {
        "id": "Wx2ZccfU8Fd7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "id": "5W0mx7Hr8xQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "8Du7OkZH84MB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#### Importando as Imagens\n",
        "### Sepando em Train and test\n",
        "## Verificando a quantidade de imagens\n",
        "\n",
        "dataset = os.path.join(os.getcwd(), 'flowers')\n",
        "\n",
        "dataset_train = os.path.join(dataset, 'train')\n",
        "dataset_train_rose = len(os.listdir(os.path.join(dataset_train, 'rose')))\n",
        "dataset_train_tulip = len(os.listdir(os.path.join(dataset_train, 'tulip')))\n",
        "\n",
        "dataset_test = os.path.join(dataset, 'test')\n",
        "dataset_test_rose = len(os.listdir(os.path.join(dataset_test, 'rose')))\n",
        "dataset_test_tulip = len(os.listdir(os.path.join(dataset_test, 'tulip')))\n",
        "\n",
        "print('Train rose: %s' % dataset_train_rose)\n",
        "print('Train tulip: %s' % dataset_train_tulip)\n",
        "print('Test rose: %s' % dataset_test_rose)\n",
        "print('Test tulip: %s' % dataset_test_tulip)"
      ],
      "metadata": {
        "id": "kzDpBa1U720s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = os.path.join(os.getcwd(), 'flowers')"
      ],
      "metadata": {
        "id": "JpektG8a9C-H"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_treinamento = gerador_treinamento.flow_from_directory('/content/flowers/train',\n",
        "                                                           target_size = (64, 64),\n",
        "                                                           batch_size = 32,\n",
        "                                                           class_mode = 'binary')"
      ],
      "metadata": {
        "id": "BFHe9ve59Obv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_teste = gerador_teste.flow_from_directory('/content/flowers/test',\n",
        "                                               target_size = (64, 64),\n",
        "                                               batch_size = 32,\n",
        "                                               class_mode = 'binary')"
      ],
      "metadata": {
        "id": "2kqcZkuj9zeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn.fit_generator(base_treinamento, steps_per_epoch = 4000 / 32,  epochs = 50, validation_data = base_teste,  validation_steps = 1000 / 32)"
      ],
      "metadata": {
        "id": "X2aonC8099kE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Realizando predições com a Rede Neural Treinada"
      ],
      "metadata": {
        "id": "FCr62muX-GFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_treinamento.class_indices"
      ],
      "metadata": {
        "id": "eX1wFsbt-M17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from keras.preprocessing import image \n",
        "from keras.utils import load_img, img_to_array"
      ],
      "metadata": {
        "id": "vz843yXM-QMr"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_orig = load_img('/content/flowers/test/tulip/tulip115.jpg')\n",
        "plt.imshow(imagem_orig)"
      ],
      "metadata": {
        "id": "3V-aUOUX-TMz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#realizando  a predição para uma imagem \n",
        "imagem_teste = load_img('/content/flowers/test/tulip/tulip115.jpg', target_size = (64,64))\n",
        "plt.imshow(imagem_teste)"
      ],
      "metadata": {
        "id": "nkC0EwuF-gZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste = img_to_array(imagem_teste)"
      ],
      "metadata": {
        "id": "oaS_fduA-1yK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste"
      ],
      "metadata": {
        "id": "OaJKxYPZ-4cQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste.shape"
      ],
      "metadata": {
        "id": "rVC_iRvA-8HL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste /= 255\n",
        "imagem_teste = np.expand_dims(imagem_teste, axis = 0)  #acrescenta uma coluna na imagem para atender o padrão do Keras "
      ],
      "metadata": {
        "id": "SZRqKZQ1-_wg"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste.shape"
      ],
      "metadata": {
        "id": "SCgQAqDC_C-p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = cnn.predict(imagem_teste)"
      ],
      "metadata": {
        "id": "JhYdbm4a_GUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "id": "Qi1Eftbh_Jd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction[0][0])\n",
        "\n",
        "if prediction[0][0] < 0.5: \n",
        "  print('Tulip')\n",
        "else: \n",
        "  print('Rose')"
      ],
      "metadata": {
        "id": "uAzJXlxK_Me4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##### Salvando e Carregando o Modelo Treinado"
      ],
      "metadata": {
        "id": "DS5wtlHJ_T20"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Salvar o modelo treinado \n",
        "cnn.save('modelRoseTulip.h5')"
      ],
      "metadata": {
        "id": "y90BMWG3_VNO"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Carregar o modelo treinado \n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "model = load_model('/content/modelRoseTulip.h5')"
      ],
      "metadata": {
        "id": "t9qHXSTJ_dro"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#realizando  a predição para uma imagem \n",
        "imagem_teste = load_img('/content/flowers/test/tulip/tulip95.jpg')\n",
        "plt.imshow(imagem_teste)"
      ],
      "metadata": {
        "id": "NsvAwGfU_qJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste = load_img('/content/flowers/test/tulip/tulip95.jpg', target_size = (64,64))\n",
        "plt.imshow(imagem_teste)"
      ],
      "metadata": {
        "id": "pZQ9fWJO_2DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste = img_to_array(imagem_teste)"
      ],
      "metadata": {
        "id": "ayPq2_EQ_9M2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste /= 255\n",
        "imagem_teste = np.expand_dims(imagem_teste, axis = 0)  #acrescenta uma coluna na imagem para atender o padrão do Keras "
      ],
      "metadata": {
        "id": "5w8KqGg9ADsc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imagem_teste.shape"
      ],
      "metadata": {
        "id": "Ur79rZ2-AIvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = model.predict(imagem_teste)"
      ],
      "metadata": {
        "id": "glGNhEoqAMOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "id": "FSgpzHUEAPP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prediction[0][0])\n",
        "\n",
        "if prediction[0][0] < 0.5: \n",
        "  print('Tulip')\n",
        "else: \n",
        "  print('Rose')"
      ],
      "metadata": {
        "id": "bLGjSBsqARuk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}